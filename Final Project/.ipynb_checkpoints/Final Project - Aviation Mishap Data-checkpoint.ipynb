{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem Statement\n",
    "Over the relatively short 118 year history of powered human flight, the human race has achieved the unachievable time and again. From the first slow short hops of the Wright brothers in 1903 to supersonic jet flight only 44 years later, and to the moon only 22 years after that, untold numbers of people have perished in the advancement of aviation technology. These days, we think almost nothing of boarding a machine that can fly us at altitudes approaching 40,000 feet at almost the speed of sound to get us from one side of the country to the other in mere hours. While the technology is proven and safe enough for us to not worry about the miniscule chance of a serious problem resulting in a devastating outcome, those problems do still arise. There are many causes for aviation mishaps and accidents, and whenever one occurs, investigators gather every possible data point that could lead to a better understanding of what happened and how to prevent it in the future.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Sets\n",
    "For this exercise, I will be analyzing aviation mishap data sets provided by the Federal Aviation Administration (FAA) Aviation Safety Information Analysis and Sharing (ASIAS) system. This system provides links to multiple source databases provided from the FAA, the National Transportation Safety Board (NTSB), the Bureau of Transportation Statistics (BTS), and the National Aeronautics and Space Administration (NASA), among others, that track various safety issues and incident and accident reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sample Questions I Seek to Answer\n",
    "I will begin with exploring the data and producing summary statistics .\n",
    "\n",
    "Questions to answer:\n",
    "What are the top 10 most common accidents or incidents?\n",
    "Of the top 10 most common events, what are the top general causes?\n",
    "What are the top primary causal factors? Contributing factors? Supporting factors?\n",
    "What is the most deadly event type? Which results in the most injuries?\n",
    "What are the top primary causal factors for the most fatal and injurious events?\n",
    "\n",
    "Does the time of day (in local time) affect rates of accident or incident?\n",
    "Does the time of year?\n",
    "\n",
    "Does the level of pilot qualification make a difference?\n",
    "Does the pilot's experience? (measured in total pilot time)\n",
    "\n",
    "What are the most prevalent accident and incident types for each of the top 5 aircraft models?\n",
    "\n",
    "More advanced and difficult questions I'd like to answer if I can:\n",
    "Are there significant groupings of primary and secondary contributing factors in aviation mishaps when looking at different types of mishaps? For example, do stall or spin mishap types occur more frequently when there is a specific combination of contributing factors (e.g., pilot-based features, aircraft-based features, weather-based features)?\n",
    "\n",
    "This would suggest that there are specific contributing factors (or groups of factors) that, if focused on via training or other resources, would have a more significant impact on aviation mishap rates for the most common or most severe/fatalmishap types.\n",
    "\n",
    "Overall analysis:\n",
    "Most common accident? Incident? both?\n",
    "Most deadly accident type? Incident type? both?\n",
    "\n",
    "Of these most common, what are the combinations of contributing factors most prevalent for these A/Is?\n",
    "\n",
    "Questions for follow-up:\n",
    "Pilot analysis:\n",
    "Does the total flight time (flight hours) of the pilot make a difference? \n",
    "Does the total number of flight hours in make/model make a difference?\n",
    "Does the number of flight hours in the preceeding 90 days make a difference?\n",
    "\n",
    "Aircraft Analysis:\n",
    "Aircraft type make a difference? \n",
    "Engine?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Challenges\n",
    "1. There are several data sets provided from multiple organizations that are each very large. This required a thorough study of each data set thoroughly to determine the best combination of data and questions to ask.\n",
    "\n",
    "2. The analysis is further complicated by the fact that the main data set refers to multiple other tables that interpret the various codes recorded in the main table. I discovered that there were additional columns in the data set that provided text for the various encoded information.\n",
    "\n",
    "3. There were many blank areas within the data set, and the data is mostly categorical in nature. I removed observations where there was no information on accident type or general causal factor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Project Execution\n",
    "This project required me to look at many different data sets from the NTSB, FAA, BTS, and NASA. I selected a dataset from the FAA's Accident/Incident Database (AIDS). This database is very thorough and spans many years (pre-1975, then each year through 2015). I began by looking at the data download site at http://av-info.faa.gov/dd_sublevel.asp?Folder=%5CAID.\n",
    "\n",
    "The data is broken down by year groups, with one text file (tab delimited) per 5 year time period. The resulting data set is massive. I began by choosing the most recent year group (2015 - 2019) which includes incidents up to July 29th, 2017. Upon further analysis (~3 hours) of this file, I determined that many data fields I was interested in were missing, most likely due to recent changes in how the data is reported and stored in this database. I then looked back and a previous date range (2005-2009) and selected that file for further analysis. This file contains 15,782 rows and 180 columns.\n",
    "\n",
    "I considered combining all data files into one DataFrame for analysis, but for the scope of this project, I chose to keep my analysis to a single file with incidents from 2005-2009. In the future, it would be interesting to conduct the same analysis on the combined data set to look at the trends of accidents and incidents over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Import sample data file from FAA Accident/Incident Database (AIDS):\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 500)\n",
    "url = './data/A2005_09.txt'\n",
    "faa_full = pd.read_table(url, sep='\\t', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faa_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Familiarization and Munging Phase\n",
    "### Getting Familiar With the Data\n",
    "In this phase I examined basic information about the data set. After I pulled the data into my notebook, I found that I did not need most of the 180 columns. I imported the data dictionary from a text file into a spreadsheet (./data/Data Dictionary.xlsx) and looked at the columns to determine those I could drop for the main data set. I annotated the spreadsheet with my keep/drop decisions by coloring the features I wished to keep as green, and those to drop as red. I also categorized the features by pilot-related characteristics, aircraft-related characteristics, and added other notes. Finally, I added a column to the dictionary to sort it. This was necessary because I noticed that related features were not located next to each other in the downloaded data set. For example, the Primary Cause Factor text (c77) and Primary Cause Factor Code (c78) were stored as columns 146 and 122, respectively. Sorting the data dictionary allowed me to easily identify these related columns and extract only the features I wanted to analyze.\n",
    "\n",
    "To facilitate the selection process I looked at value_counts() for each feature and compared the results to the Data Dictionary to get a feel for the data contained within and to further inform the features I would keep or drop. Based on sorting and analyzing value_counts, I realized that there were multiple columns that represented the same data. For example, several date and time fields were represented as both separate year, month, day, time columns and again as a combined column. Also, many of the columns are encoded (key is found in './data/AIDCODES.doc') with the same data recorded in plain text in another column. In these cases, I chose to keep the plain text and drop the encoded column.\n",
    "### Munging\n",
    "Once I completed my initial look at the data and the data dictionary, I went through the following steps to make it more manageable:\n",
    "1. I dropped the columns I determined I would not need for this analysis.\n",
    "2. I renamed the remaining columns to plain-language names\n",
    "3. I dropped all rows that did not have any primary causal factors listed.\n",
    "4. I dropped rows with no accident type listed.\n",
    "5. After further analysis of the data, I decided to drop more columns. I originally had 42, and ultimately ended up with 15.\n",
    "\n",
    "As some of the questions I wanted to examine would need some features while others would not, I kept the 'faa' dataset as whole as possible, and peeled off subsets of the data into separate dataframes as needed for my analysis.\n",
    "\n",
    "### Final Data Features ~~(42)~~ (15)\n",
    "| Column Name | Description |\n",
    "| :------ | -------- | \n",
    "| ~~event_type~~ | ~~Type of Event~~ |\n",
    "| date | Date the accident/incident happened |\n",
    "| local_time | Local time of the accident/incident |\n",
    "| num_engines | Number of engines on aircraft |\n",
    "| ~~make~~ | ~~Make of the aircraft~~ |\n",
    "| ~~model~~ | ~~Model of the aircraft~~ |\n",
    "| ~~airframe_hours~~ | ~~Airframe hours of the aircraft~~ |\n",
    "| ~~lat~~ | ~~Latitude coordinates of the accident/incident~~ |\n",
    "| ~~long~~ | ~~Longitude coordinates of the accident/incident~~ |\n",
    "| fatalities | Total Fatalities |\n",
    "| injuries | All injuries including crew passengers and public |\n",
    "| pilot_age | Age of the pilot in command |\n",
    "| ~~pilot_total_hours_model~~ | ~~Total number of hours the pilot has flown in the specific make and model of the aircraft~~ | \n",
    "| ~~pilot_90_day_hours_model~~ | ~~Total number of hours in the last 90 days the pilot has flown this make and model~~ |\n",
    "| ~~pilot_90_day_hours~~ | ~~Total number of hours in the last 90 days the pilot  has flown~~ |\n",
    "| pilot_total_hours | Total number of hours the pilot has flown |\n",
    "| flight_plan_desc | Flight plan description |\n",
    "| pilot_cert | Certificate type text of the pilot in command |\n",
    "| ~~pilot_qual~~ | ~~Qualification description of the pilot in command~~ |\n",
    "| primary_cause | Primary cause factor text |\n",
    "| ~~contributing_factor~~ | ~~Contributing factor text~~ |\n",
    "| ~~persons_involved~~ | ~~Persons involved text~~ |\n",
    "| ~~supporting_factor_technical~~ | ~~Supporting factor text - Technical~~ |\n",
    "| ~~second_cause~~|~~Second cause factor text~~|\n",
    "| ~~second_contributing~~ | ~~Second contributing factor text~~ |\n",
    "| ~~second_persons~~ | ~~Second persons involved text~~ |\n",
    "| ~~second_supporting_technical~~ | ~~Second supporting factor text - Technical~~ |\n",
    "| accident_type | Type of accident or incident text |\n",
    "| flight_phase | Phase of flight text |\n",
    "| ~~damage~~ | ~~Damage text~~ |\n",
    "| general_cause | General cause category text |\n",
    "| primary_flying_conditions | Primary flying condition text |\n",
    "| second_flying_conditions | Secondary flying condition text |\n",
    "| ~~light_condition~~ | ~~Light condition text~~ |\n",
    "| ~~wing_info~~ | ~~Wing information of the aircraft text~~ |\n",
    "| ~~powered~~ | ~~Text for element C150 (Powered, Nonpowered, Optional)~~ |\n",
    "| ~~engine_type~~ | ~~Type of engine~~ |\n",
    "| ~~landing_gear~~ | ~~Type of landing gear~~ |\n",
    "| ~~additional_cause~~ | ~~Additional cause factor text~~ |\n",
    "| ~~2nd_additional_cause~~ | ~~2nd Additional cause factor text~~ |\n",
    "| ~~supporting_factor_operational~~ | ~~Supporting factor Text - Operational~~ |\n",
    "| ~~second_supporting_operational~~ | ~~Second supporting factor text - Operational~~|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Munging Phase\n",
    "\n",
    "#Drop unwanted columns from dataset.\n",
    "\n",
    "#I broke up the list of columns I wanted to drop as I determined them to reduce my chances of error.\n",
    "droplist = ['c2','c3','c4','c5','c6','c7','c8','c11','c12','c13','c14','c15','c16','c17','c18','c19','c22','c25']\n",
    "droplist = droplist + ['c26','c27','c30','c32','c33','c34','c35','c36','c37','c38','c39', 'c41','c43','c44','c45','c46','c47','c49']\n",
    "droplist = droplist + ['c51','c52','c57','c58','c59','c61','c62','c63','c64','c65','c66','c67','c68','c69','c70','c71','c72','c73']\n",
    "droplist = droplist + ['c74','c75','c78','c80','c82','c84','c86','c88','c90','c96','c98','c101','c102','c103','c104']\n",
    "droplist = droplist + ['c106','c108','c110','c111','c112','c113','c114','c115','c117','c118','c119','c120','c121','c122','c123','c124']\n",
    "droplist = droplist + ['c125','c126','c127','c128','c129','c131','c132','c133','c134','c135','c136','c137','c138','c139','c140']\n",
    "droplist = droplist + ['c141','c143','c144','c145','c146','c147','c149','c152','c153','c154','c155','c157','c160','c162','c184','c192']\n",
    "droplist = droplist + ['c203','c204','c205','c206','c207','c208','c210','c214','c229','c230','c233','c234','c240','c241','c242']\n",
    "droplist = droplist + ['c243','c244','c790','end_of_record','c92','c94','c100']\n",
    "faa_full = faa_full.drop(droplist, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "faa_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I created plain-language column names that aligned with the data dictionary added them in the same order as the columns\n",
    "columnlist=['event_type','date','local_time','num_engines','make','model','airframe_hours','lat','long']\n",
    "columnlist = columnlist + ['fatalities','injuries','pilot_age','pilot_total_hours_model','pilot_90_day_hours_model']\n",
    "columnlist = columnlist + ['pilot_90_day_hours','pilot_total_hours','flight_plan_desc','pilot_cert','pilot_qual']\n",
    "columnlist = columnlist + ['primary_cause','contributing_factor','persons_involved','supporting_factor_technical']\n",
    "columnlist = columnlist + ['second_cause','second_contributing','second_persons','second_supporting_technical']\n",
    "columnlist = columnlist + ['accident_type','flight_phase','damage','general_cause','primary_flying_conditions']\n",
    "columnlist = columnlist + ['second_flying_conditions','light_condition','wing_info','powered','engine_type']\n",
    "columnlist = columnlist + ['landing_gear','additional_cause','2nd_additional_cause','supporting_factor_operational']\n",
    "columnlist = columnlist + ['second_supporting_operational']\n",
    "len(columnlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "faa_full.columns = columnlist # Renamed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "faa_full.head() # Sanity check on column labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After further analysis, I returned to this portion of the notebook to drop more columns, as described above\n",
    "\n",
    "droplist2 = ['event_type','make','model','airframe_hours','lat','long','contributing_factor','persons_involved']\n",
    "droplist2 = droplist2 + ['supporting_factor_technical','second_cause','second_contributing','second_persons']\n",
    "droplist2 = droplist2 + ['second_supporting_technical','damage','light_condition','wing_info','powered','engine_type']\n",
    "droplist2 = droplist2 + ['landing_gear','additional_cause','2nd_additional_cause','supporting_factor_operational']\n",
    "droplist2 = droplist2 + ['second_supporting_operational','pilot_total_hours_model','pilot_90_day_hours_model']\n",
    "droplist2 = droplist2 + ['pilot_90_day_hours', 'pilot_qual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faa_full = faa_full.drop(droplist2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faa_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I replaced all blank values in the primary cause and accident type columns with NaN\n",
    "\n",
    "# In order to determine what exactly was in the blank values, I used:\n",
    "# causes = pd.DataFrame(faa_full.general_cause.value_counts())\n",
    "# causes.index\n",
    "# Then I copied the number of spaces into the replace statement below:\n",
    "# faa_full.replace('                    ', np.nan, inplace=True)\n",
    "\n",
    "#Later, (after much pain) I found that I could strip all the whitespace across the DataFrame with a function:\n",
    "def df_strip(df): \n",
    "  df = df.copy() \n",
    "  for c in df.columns:\n",
    "    if df[c].dtype == np.object:\n",
    "      df[c] = pd.core.strings.str_strip(df[c])\n",
    "  return df\n",
    "\n",
    "faa_full = df_strip(faa_full); # Calls above function to strip whitespace\n",
    "# Then I could easily replace the blank cells with NaN, and drop any columns or rows easily.\n",
    "faa_full.replace('', np.nan, inplace=True) # Replaces empty cells with NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "faa_full.dropna(subset=['general_cause','accident_type'], inplace=True)\n",
    "#faa_full['date']=faa_full['date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faa_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faa_full.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace \"NaN\" in object columns with \"unknown\" category\n",
    "def df_unknown(df): \n",
    "  df = df.copy() \n",
    "  for c in df.columns:\n",
    "    if df[c].dtype == np.object:\n",
    "        df[c] = df[c].replace(np.nan, 'Unknown')\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "faa_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faa_full['pilot_qual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot showing the top 10 types of accidents\n",
    "top_accidents = faa_full.accident_type.value_counts().head(10).plot(kind='bar', figsize = (12,8))\n",
    "top_accidents.set_xlabel('Accident Types', fontsize=16, labelpad=10)\n",
    "top_accidents.set_ylabel('Number of Accidents', fontsize=16)\n",
    "top_accidents.set_title('Top 10 Accidents by Type', fontsize=20, y=1.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pull all accidents with fatalities\n",
    "fatal_accidents = faa_full[faa_full['fatalities'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot showing the top 10 fatal accidents, by # of occurrences\n",
    "top_fatal = fatal_accidents.accident_type.value_counts().head(10).plot(kind='bar', figsize = (12,8))\n",
    "top_fatal.set_xlabel('Accident Types', fontsize=16, labelpad=10)\n",
    "top_fatal.set_ylabel('Number of Accidents', fontsize=16)\n",
    "top_fatal.set_title('Top 10 Fatal Accidents by Type (Occurance)', fontsize=20, y=1.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of top 10 fatal accident types, by total number of fatalities. Of note, The \"Overshoot Landing\" accident type\n",
    "#     was only one event, which resulted in 49 fatalities.\n",
    "fatal = fatal_accidents[['accident_type', 'fatalities']].groupby('accident_type').sum()\\\n",
    "                                                .sort_values('fatalities',ascending=False)\\\n",
    "                                                .head(10).plot(kind='bar', figsize=(12,8))\n",
    "fatal.set_xlabel('Accident Types', fontsize=16, labelpad=10)\n",
    "fatal.set_ylabel('Fatalities', fontsize=16)\n",
    "fatal.set_title('Top 10 Fatal Accidents by Type (Fatalities)', fontsize=20, y=1.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fatal_accidents['primary_cause'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatal_accidents['general_cause'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull all accidents with injuries\n",
    "injury_accidents = faa_full[faa_full['injuries'] > 0]\n",
    "injury_accidents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_injury = injury_accidents[['accident_type','injuries']].groupby('accident_type').sum()\\\n",
    "                                              .sort_values('injuries', ascending=False)\\\n",
    "                                              .head(10).plot(kind='bar', figsize=(12,8))\n",
    "top_injury.set_xlabel('Accident Types', fontsize=16, labelpad=10)\n",
    "top_injury.set_ylabel('Injuries', fontsize=16)\n",
    "top_injury.set_title('Top 10 Injurious Accidents by Type (Injuries)', fontsize=20, y=1.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "injury_accidents['primary_cause'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "injury_accidents['general_cause'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Observations from EDA\n",
    "Based on my inital examination of the data, I concluded that I needed to further simplify my analysis for this project. To that end, I decided to focus on those fatal and injurious accidents that were pilot induced.\n",
    "\n",
    "I created a subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatal_accidents.pilot_cert.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatal_pilot_cert = fatal_accidents[['pilot_cert', 'fatalities']].groupby('pilot_cert').sum()\\\n",
    "                                                .sort_values('fatalities',ascending=False)\\\n",
    "                                                .head(10).plot(kind='bar', figsize=(12,8))\n",
    "fatal_pilot_cert.set_xlabel('Pilot Certs', fontsize=16, labelpad=10)\n",
    "fatal_pilot_cert.set_ylabel('Fatalities', fontsize=16)\n",
    "fatal_pilot_cert.set_title('Top 10 Fatal Accidents by Pilot Certs', fontsize=20, y=1.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatal_accidents.plot(kind='scatter', x='pilot_total_hours', y='fatalities', alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.swarmplot(x=\"fatalities\", y=\"pilot_cert\", data=fatal_accidents);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"fatalities\", y=\"pilot_cert\", data=fatal_accidents);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatal_accidents.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "X = fatal_accidents[['pilot_total_hours', 'pilot_age']]\n",
    "y = fatal_accidents.fatalities\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.fit(X_train,y_train)\n",
    "y_pred = LR.predict(X_test)\n",
    "LR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
